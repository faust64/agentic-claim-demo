# Complete Llama Stack Configuration for Claims Demo
# Includes: Inference, Agents, Safety, Eval, Scoring, Tool Runtime (MCP), Vector IO
version: "2"
image_name: rh

# APIs to enable
apis:
- agents
- datasetio
- files
- inference
- safety        # Added for guardrails
- eval          # Added for evaluation
- scoring
- tool_runtime
- vector_io

# Providers configuration
providers:
  # ============================================================================
  # INFERENCE PROVIDERS
  # ============================================================================
  inference:
    # Embedding provider (inline)
    - provider_id: sentence-transformers
      provider_type: inline::sentence-transformers
      config: {}

    # Main LLM: Llama 3.2 3B Instruct with tool calling
    - provider_id: vllm-inference-1
      provider_type: remote::vllm
      config:
        api_token: ${env.VLLM_API_TOKEN_1:=fake}
        max_tokens: ${env.VLLM_MAX_TOKENS:=16384}
        tls_verify: ${env.VLLM_TLS_VERIFY:=false}
        url: http://llama-instruct-32-3b-predictor.llama-instruct-32-3b-demo.svc.cluster.local:80/v1

    # Alternative LLM: Mistral 3 14B for complex tasks
    - provider_id: vllm-inference-2
      provider_type: remote::vllm
      config:
        api_token: ${env.VLLM_API_TOKEN_2:=fake}
        max_tokens: ${env.VLLM_MAX_TOKENS:=16384}
        tls_verify: ${env.VLLM_TLS_VERIFY:=false}
        url: http://mistral-3-14b-instruct-predictor.edg-demo.svc.cluster.local:80/v1

  # ============================================================================
  # SAFETY PROVIDERS (Guardrails)
  # ============================================================================
  safety:
    # Llama Guard 3 8B - Content safety classification
    - provider_id: llama-guard
      provider_type: inline::llama-guard
      config:
        model: meta-llama/Llama-Guard-3-8B
        excluded_categories: []  # Enable all safety categories

    # Prompt Guard 86M - Jailbreak/injection detection
    - provider_id: prompt-guard
      provider_type: inline::prompt-guard
      config:
        model: meta-llama/Prompt-Guard-86M

  # ============================================================================
  # AGENTS PROVIDER
  # ============================================================================
  agents:
    - provider_id: meta-reference
      provider_type: inline::meta-reference
      config:
        persistence_store:
          db_path: /opt/app-root/src/.llama/distributions/rh/agents_store.db
          namespace: null
          type: sqlite
        responses_store:
          db_path: /opt/app-root/src/.llama/distributions/rh/responses_store.db
          type: sqlite

  # ============================================================================
  # EVAL PROVIDER
  # ============================================================================
  eval:
    - provider_id: meta-reference-eval
      provider_type: inline::meta-reference
      config:
        kvstore:
          db_path: /opt/app-root/src/.llama/distributions/rh/eval_store.db
          namespace: null
          type: sqlite

  # ============================================================================
  # SCORING PROVIDERS
  # ============================================================================
  scoring:
    - provider_id: basic
      provider_type: inline::basic
      config: {}

    - provider_id: llm-as-judge
      provider_type: inline::llm-as-judge
      config: {}

  # ============================================================================
  # TOOL RUNTIME PROVIDERS
  # ============================================================================
  tool_runtime:
    # Built-in RAG runtime
    - provider_id: rag-runtime
      provider_type: inline::rag-runtime
      config: {}

    # Model Context Protocol (MCP) for custom tools
    - provider_id: model-context-protocol
      provider_type: remote::model-context-protocol
      config:
        # MCP servers will be registered dynamically via tool_groups below
        {}

  # ============================================================================
  # VECTOR IO PROVIDER
  # ============================================================================
  vector_io:
    - provider_id: milvus
      provider_type: inline::milvus
      config:
        db_path: /opt/app-root/src/.llama/distributions/rh/milvus.db
        kvstore:
          db_path: /opt/app-root/src/.llama/distributions/rh/milvus_registry.db
          namespace: null
          type: sqlite

  # ============================================================================
  # FILES PROVIDER
  # ============================================================================
  files:
    - provider_id: meta-reference-files
      provider_type: inline::localfs
      config:
        metadata_store:
          db_path: /opt/app-root/src/.llama/distributions/rh/files_metadata.db
          type: sqlite
        storage_dir: /opt/app-root/src/.llama/distributions/rh/files

  # ============================================================================
  # DATASET IO PROVIDER
  # ============================================================================
  datasetio:
    - provider_id: huggingface
      provider_type: remote::huggingface
      config:
        kvstore:
          db_path: /opt/app-root/src/.llama/distributions/rh/huggingface_datasetio.db
          namespace: null
          type: sqlite

# ============================================================================
# METADATA STORE
# ============================================================================
metadata_store:
  type: sqlite
  db_path: /opt/app-root/src/.llama/distributions/rh/inference_store.db

# ============================================================================
# MODELS
# ============================================================================
models:
  # Embedding model
  - provider_id: sentence-transformers
    model_id: granite-embedding-125m
    provider_model_id: ibm-granite/granite-embedding-125m-english
    model_type: embedding
    metadata:
      embedding_dimension: 768
      max_sequence_length: 512
      description: "IBM Granite embedding model for English text"

  # Main LLM: Llama 3.2 3B Instruct
  - provider_id: vllm-inference-1
    model_id: llama-instruct-32-3b
    model_type: llm
    metadata:
      description: "Llama 3.2 3B Instruct with tool calling support"
      display_name: llama-instruct-32-3b
      context_length: 8192
      max_tokens: 16384

  # Alternative LLM: Mistral 3 14B Instruct
  - provider_id: vllm-inference-2
    model_id: mistral-3-14b-instruct
    model_type: llm
    metadata:
      description: "Mistral 3 14B Instruct for complex tasks"
      display_name: mistral-3-14b-instruct
      context_length: 32768

  # Safety model: Llama Guard 3 8B
  - provider_id: llama-guard
    model_id: llama-guard-3-8b
    provider_model_id: meta-llama/Llama-Guard-3-8B
    model_type: safety
    metadata:
      description: "Content safety classification model"
      categories:
        - violent_crimes
        - non_violent_crimes
        - sex_crimes
        - child_exploitation
        - defamation
        - specialized_advice
        - privacy
        - intellectual_property
        - indiscriminate_weapons
        - hate
        - self_harm
        - sexual_content
        - elections
        - code_interpreter_abuse

  # Safety model: Prompt Guard 86M
  - provider_id: prompt-guard
    model_id: prompt-guard-86m
    provider_model_id: meta-llama/Prompt-Guard-86M
    model_type: safety
    metadata:
      description: "Jailbreak and injection detection model"

# ============================================================================
# SHIELDS (Guardrails)
# ============================================================================
shields:
  # Llama Guard shield for input/output filtering
  - shield_id: llama-guard-shield
    provider_id: llama-guard
    shield_type: llama_guard
    params:
      model: llama-guard-3-8b
      excluded_categories: []  # All categories enabled

  # Prompt Guard shield for jailbreak detection
  - shield_id: prompt-guard-shield
    provider_id: prompt-guard
    shield_type: prompt_guard
    params:
      model: prompt-guard-86m

# ============================================================================
# TOOL GROUPS
# ============================================================================
tool_groups:
  # Built-in RAG tools
  - toolgroup_id: builtin::rag
    provider_id: rag-runtime

  # MCP Claims Processing Tools (to be registered dynamically)
  # These will be registered via API when MCP servers are deployed
  # Format: mcp::<server-name>::<tool-name>
  # Example registration command:
  # curl -X POST http://llamastack:8321/v1/toolgroups/register \
  #   -d '{
  #     "toolgroup_id": "mcp::claims-processing",
  #     "provider_id": "model-context-protocol",
  #     "mcp_endpoint": {
  #       "uri": "sse://ocr-mcp-server.claims-demo.svc.cluster.local:8080"
  #     },
  #     "tools": ["ocr_document"]
  #   }'

# ============================================================================
# VECTOR DATABASES
# ============================================================================
vector_dbs:
  - vector_db_id: claims-milvus
    provider_id: milvus
    embedding_model: granite-embedding-125m
    embedding_dimension: 768
    metadata:
      description: "Vector DB for claims and contracts embeddings"

# ============================================================================
# DATASETS (for evaluation)
# ============================================================================
datasets:
  - dataset_id: claims-eval-dataset
    provider_id: huggingface
    url: local://claims-test-data
    metadata:
      description: "Claims processing evaluation dataset"
      num_samples: 100
      split: test

# ============================================================================
# SCORING FUNCTIONS (for evaluation)
# ============================================================================
scoring_fns:
  # Claims accuracy scoring using LLM-as-judge
  - scoring_fn_id: claims-accuracy
    provider_id: llm-as-judge
    params:
      type: llm_as_judge
      judge_model: llama-instruct-32-3b
      judge_score_regexes:
        - '(?i)accuracy:\s*([0-5])'
      prompt_template: |
        Evaluate the accuracy of this claim decision on a scale of 1-5:

        Claim Data: {claim_data}
        User Contract: {user_contract}
        Similar Claims: {similar_claims}
        Decision: {decision}
        Reasoning: {reasoning}

        Criteria:
        - Contract coverage alignment (2 points)
        - Historical claims consistency (2 points)
        - Document evidence quality (1 point)

        Provide your evaluation in the format: "Accuracy: X" where X is 1-5

  # OCR quality scoring
  - scoring_fn_id: ocr-quality
    provider_id: basic
    params:
      type: regex_parser_multiple_choice_answer
      parsing_regexes:
        - 'confidence:\s*([0-9.]+)'

# ============================================================================
# BENCHMARKS
# ============================================================================
benchmarks:
  - benchmark_id: claims-processing-bench
    dataset_id: claims-eval-dataset
    scoring_functions:
      - claims-accuracy
      - ocr-quality
    metadata:
      description: "End-to-end claims processing evaluation"
      metrics:
        - accuracy
        - precision
        - recall
        - f1_score

# ============================================================================
# SERVER CONFIGURATION
# ============================================================================
server:
  port: 8321
  cors:
    allowed_origins: ["*"]
    allowed_methods: ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
    allowed_headers: ["*"]
